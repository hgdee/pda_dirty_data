---
title: "D12 Dirty Data Project"
output:
  html_document: 
    number_sections: yes
    toc: yes
    df_print: paged
    toc_float: yes
---

```{r}
library(tidyverse)
library(here)
library(janitor)
library(stringr)
library(readxl)
library(psych)
library(assertr)
library(testthat)
```

1 MVP
1.1 Task 1 - Decathlon Data
This data is contained in the .rds file decathlon.rds. You’ll need to use read_rds() from readr to open it.

# Call R file to process the rds file.
 


# Outline of the decathlon data and analysis
The decathlon data is a small dataset of the decastar and olympic decathlon competitions. It is not clear to me which year, and dates, the data was derived from.

I have made no significant assumptions about the data and have no reason to doubt the accuracy of the data. The data seems to be generally clean and viable.

The initial steps of cleaning were to turn rownames into a column called competitor, which will make analysis easier.  I relied on janitor's clean_names to amend the case and column names otherwise.

The analysis code is below but overall my conclusions are, unsurprisingly, the same competitors were at the top of both competitions and that results were better in the olympic games.


# This file calls in the data and does the wrangling.
```{r}
source(here::here("R_scripts/read_rds_data.R"))
```

```{r}

decathlon_data  <- read_rds(here::here("Cleaned_data/decathlon_data.rds"))
```


# 1.1.2 Analysis questions
  ## 1 Who had the longest long jump seen in the data?
```{r}
decathlon_data %>% 
  filter(long_jump == max(long_jump)) %>%
  select(competitor, long_jump, competition)
```
The current olympic record is 8.95 so this result is way short of that record, but is higher than the olympic decathlon record of 7.72 - held by Sebrle.

## 2 What was the average 100m time in each competition?
```{r}
decathlon_data %>% 
  group_by(competition) %>%
   summarise(mean(x100m))
```
As expected, the olympic time is better than the decastar as it is more prestigious and comeptitors would build training to peak at the games.  
  
## 3 Who had the highest total points across both competitions?
```{r}
decathlon_data %>% 
  filter(points== max(points))
```
 Sebrle got 8893 points and the olympic record is Kevin Mayer 9126 pts (2018)
 
## 4 What was the shot-put scores for the top three competitors in each competition?
```{r}
rbind(decathlon_data %>% 
  filter(competition == "olympicg") %>%
  select(competition,competitor,shot_put) %>%
  group_by(competition, competitor) %>%
  arrange(desc(shot_put)) %>%
  head(3), 
  decathlon_data %>% 
  filter(competition == "decastar") %>%
  select(competition,competitor,shot_put) %>%
  group_by(competition, competitor) %>%
  arrange(desc(shot_put)) %>%
  head(3))

```
  
The usual suspects dominate.


## 5 What was the average points for competitors who ran the 400m in less than 50 seconds vs. those than ran 400m in more than 50 seconds?


```{r}
rbind(decathlon_data  %>%
    filter(x400m < 50) %>%
    summarise(round(mean(points),2 )) %>%
    distinct() %>%
    paste( " average points where 400m < 50 secs"),
  decathlon_data  %>%
    filter(x400m >= 50) %>%
    summarise( round(mean(points),2)) %>%
    distinct() %>%
    paste( " average points where 400m >= 50 secs")
)

```

# 1.4 Task 4 - Halloween Candy Data
The data is in files boing-boing-candy-2015.xlxs, boing-boing-candy-2016.xlxs and boing-boing-candy-2017.xlxs. Bear in mind that this is trickier compared with tasks 1, 2 & 3.

The candy data sets revolved around consumer opinion of candy bar brands.

The three datasets were very dirty with various issues and inconsistencies, such as missing timestamps, gender and, also, invalid answers, such as ages of 300. 

However, the cleaned and combined dataset was valuable having over 9000 rows with circa 75 obervations of customer opinion of candy bar brands.

Wrangling was broken down into two R files to simplify understanding.  Many columns were superflous and removed. Some were renamed. Timestamps were converted to a simple year identification.
read_in_candy_data.R reads in the xlsx files and attends to missing columns and getting consistent country names (significant numbers of invalid names) and timestamps (year names) and so on. Missing 2015 data for country and gender was created via a 'for loop' utilising 2016 data. That might skew any statistics but seemed a valid  way of creating viable data for analysis.
```{r}

source(here::here("R_scripts/read_in_candy_data.R"))


```

This second call in the wrangling process drops unwanted columns and writes the merged and cleaned data to a new directoryt before reading it in below.

# Now the three years of data need to be merged. 

```{r}

source(here::here("R_scripts/drop_cols_and_merge.R"))

```

This is the backed up and cleaned data.
```{r}
candy_data <- read_rds(here::here("Cleaned_data/candy_data.rds"))
```



```{r}
glimpse(candy_data)

```


# 1.4.2 Analysis questions

## 1. What is the total number of candy ratings given across the three years. (number of candy ratings, not number of raters. Don’t count missing values)

This figure was obtained by pivoting and then simply summarising the ratings
```{r}
candy_long <- candy_data  %>%
    pivot_longer(cols=6:80, values_drop_na = TRUE) 

   candy_long %>% summarise(sum(n()))

 
```


## 2. What was the average age of people who are going out trick or treating and the average age of people not going trick or treating?

As there were many responses that skewed the data, by a few years, it was decided to restrict the age range to provide this answer.

```{r}

  # as many ages are implausible (0-300) restrict the age to 5-100
candy_data %>%
  select(are_you_going_actually_going_trick_or_treating_yourself, 
          how_old_are_you) %>%
  filter(how_old_are_you >= 5 & how_old_are_you <= 100) %>%
  drop_na() %>%
  group_by(are_you_going_actually_going_trick_or_treating_yourself) %>%
  summarise(mean = round(mean(how_old_are_you)))

```
The responses probably shows a decline in enthusiasm for trick or treating as age increases. There may well be other factors, such as fears over security, that would amend this assumption and that in turn may relate to social environments, i.e. country or urban settings.

## 3. For each of joy, despair and meh, which candy bar received the most of these ratings?

This call simply creates the pivot data.
```{r}
pivot_candy <- candy_data  %>%
    pivot_longer(cols=6:80,   names_to = "candy_bar_name", 
                              values_to = "customer_satisfaction",
                              values_drop_na = TRUE)
```


```{r}

pivot_candy %>% 
      group_by(customer_satisfaction,candy_bar_name)  %>%
      select(candy_bar_name,customer_satisfaction)  %>%
      count() %>%
      summarise(customer_satisfaction, n) %>%
      arrange(customer_satisfaction, desc(n)) %>%
      slice_max(n, n = 1)

     
```
Gum is generally bland and so it is not hugely surprising that gum from baseball cards - probably bought for the baseball cards as opposed to the gum - should be unpopular. 

Ambivalence to lollipops, is perhaps surprising as other surveys, such as reported on by Newsweek https://www.newsweek.com/why-kids-pick-some-treats-over-others-73667 suggests that young children tend to go for high sugar content and items not usually available in vending machines.

KitKats are universally popular over a large age range and most global cultures - and so it is not hugely surprising that they are popuplar in the survey.

https://www.referralcandy.com/blog/kit-kat-marketing-strategy/  suggests that:

Recap: How did Kit Kat achieve such popularity?
Consistent branding with a strong tagline
Innovative flavors keep people talking about the product
‘Moment Marketing’ helps them connect with fans and acknowledge them
Collaborations with other brands helps to bring in excitement about Kit Kats

## 4 How many people rated Starburst as despair?

```{r}
pivot_candy %>% 
      group_by(candy_bar_name)  %>%
      filter(toupper( candy_bar_name) == "STARBURST" & 
                      customer_satisfaction == "DESPAIR") %>%
      select(candy_bar_name, customer_satisfaction) %>%
      count() 
```
This fairly high number of negative reactions to Starburst is, perhaps, surprising as it is a popular brand that has been around since the 1960's. No insights can be offered to this response.

# For the next three questions, count despair as -1, joy as +1 and meh as 0.


```{r}


pivot_candy[pivot_candy == "JOY"] <-     "1"
pivot_candy[pivot_candy == "MEH"] <-     "0"
pivot_candy[pivot_candy == "DESPAIR"] <- "-1"
pivot_candy$customer_satisfaction <- as.numeric(pivot_candy$customer_satisfaction)


# As 'other' and 'I'd ratuher not say' look to be the same then combine 
# NA's are not converted
pivot_candy[pivot_candy == "I'd rather not say"] <- "Other"
```

## 6 (?) What was the most popular candy bar by this rating system for each gender in the dataset?
```{r}
pivot_candy %>%
  select(your_gender,  candy_bar_name, customer_satisfaction)  %>%
  filter(!is.na(your_gender))  %>%
  group_by(your_gender,candy_bar_name) %>%
  summarise( sum = sum(customer_satisfaction))  %>%
  arrange(your_gender, desc(sum))  %>%
  slice_max(sum, n = 1)
```
As above, KitKat, due to flavour, balance and marketing is universally popular.


# 7 What was the most popular candy bar in each year?


```{r}
  pivot_candy %>%
  select(timestamp,  candy_bar_name, customer_satisfaction)  %>%
  group_by(timestamp,candy_bar_name) %>%
  summarise( sum = sum(customer_satisfaction))  %>%
  arrange(timestamp, desc(sum))  %>%
  slice_max(sum, n = 1)
```
This result was surprising as the figure for reese_s_peanut_butter_cups was high - though there was more 2015 data so that would skew the sum by comparison to other years. It was also surprising that reeses_pieces were so popular in 2017. This may raise questions about whether the data collected in 2017 was made in a consistent way with previous years.  It laos possibly conflicts with previous answers where data was assesed in other ways, by gender for instance. However, this Hershey product would be expected to be popular,

# 8. What was the most popular candy bar by this rating for people in US, Canada, UK and all other countries?



```{r}


country_candy <- pivot_candy %>%
        mutate(country =  
          case_when(country  
                      %in% c("usa","canada","united kingdom") ~
                      country, 
                      TRUE ~ "other" )) %>%
        select(country,  
             candy_bar_name, 
             customer_satisfaction)  %>%
        filter(!is.na(country)) %>%
        group_by(country, candy_bar_name) %>%
        summarise( sum = sum(customer_satisfaction) )  

country_candy %>%
    slice_max(sum, n = 1) %>%   
  arrange(  country, sum, candy_bar_name)  


```
By contrast to the previous question these results would be anticipated and are in line with other results obtained.

# 2 Extensions

## The data is available in the file rwa.csv. This dataset comes from https://openpsychometrics.org/_rawdata/. It measures how people score on a measure called Right Wing Authoritarianism, or RWA.

### 2.1.1 Some cleaning hints
You’ll need to calculate people’s overall RWA score. This is found from the mean of questions 3 to 22. Questions 1 and 2 are warm up questions. Note that the following questions are reverse scored: 4, 6, 8, 9, 11, 13, 15, 18, 20, 21.
Read the file rwa_codebook.txt to understand how to clean this data. [Hint: you may want to recode some of the variables to give their values meaning].


# Read in the data
```{r}
source(here::here("R_scripts/read_in_rwa_data.R"))
```


```{r}
rwa_data <- read_rds(here::here("Cleaned_data/rwa_data.rds"))
```

```{r}
glimpse(rwa_data)

rwa_data %>%
  select(starts_with("q" ), rwa_score) %>%
  head(2)
```


#  2.1.2 Analysis questions
## 1. What’s the average RWA score for each gender?
```{r}

rwa_data %>%
  select(gender, rwa_score) %>%
  filter(!gender == 0) %>%
  group_by(gender) %>%
  summarise( mean(rwa_score)) 

```

##  2. What’s the average RWA score for left handed people vs. right handed people.

```{r}
rwa_data %>%
  select(hand, rwa_score) %>%
  filter(!hand == 0) %>%
  group_by(hand) %>%
  summarise( mean(rwa_score)) 
```
## 3. What’s the average family size for each type of childhood?

```{r}

rwa_data %>%
  select(urban, familysize) %>%
  filter(!urban == 0) %>%
  group_by(urban) %>%
  summarise( round(mean(familysize)))
```

## 4  What’s the average time to take the test for each education level?
```{r}
rwa_data %>%
  select(education, testelapse) %>%
  filter(!education == 0) %>%
  group_by(education) %>%
  summarise( round(mean(testelapse)))

```
## 5. Create a plot of results of question 4.

```{r}
data <- rwa_data %>%
  select(education, testelapse) %>%
  filter(!education == 0) %>%
  group_by(education) %>%
  summarise( round(mean(testelapse)))
education <- table(data)
plot(education)
```

## 6. What’s the average RWA score for people aged
Under 18
18 to 25
26 to 40
41 to 60

```{r}

rwa_data %>% 
  select(age, rwa_score) %>%
  mutate(age_cuts = cut(age, c(0,18,25,26,40,41,60))) %>%
  filter(!is.na(age_cuts)) %>%
  group_by(age_cuts) %>%
  summarise(avg_rwa_score =round(mean(rwa_score)))

```

# 2.2 Task 6 - Dog owners survey
The data is available in the file dog_survey.csv It is the results of a survey filled in by dog owners about their dogs.

# Read in the data
```{r}
source(here::here("R_scripts/read_in_dog_survey.R"))

```


```{r}
glimpse(dog_survey)

```

# 2.2.2 Analysis questions

## 1. The client only counts a valid email address as one ending in ‘.com’. How many survey results have a valid email address.
```{r}
dog_survey %>%
 select(email, contains(".com")) %>%
  summarise(valid_email_addresses = sum(n()))
  
```


## 2. What’s the average amount spent on dog food for each dog size.

```{r}
"%ni%" <- Negate("%in%")
dog_sums <- dog_survey %>%
              filter(!is.na(amount_spent_on_dog_food)) %>%
              filter( dog_size != "NA") %>%
              filter(dog_size %ni% c( "NO","N/A")) %>%
              group_by(dog_size) 
dog_sums %>% 
  summarise(mean(amount_spent_on_dog_food))
```

## 3. For owners whose surname starts with a letter in the second half of the alphabet (N onwards) what is the average age of their dog?

```{r}

dog_sums <- dog_survey %>%
  filter(substr(last_name,1,1) >= "N") 

dog_sums %>%
  summarise(average_dog_age_for_names_N_onwards = round(mean(dog_age)))

```

## 4. The dog_age column is the age in dog years. If the conversion is 1 human year = 6 dog years, then what is the average human age for dogs of each gender?

```{r}
 dog_survey %>%
              filter(!is.na(dog_age)) %>%
              group_by(dog_gender) %>%
              summarise(human_years_dog_age = round(mean(dog_age/6)))


```

## 5. Create a plot of results of question 4.

```{r}
dog_sums <- dog_survey %>%
              filter(!is.na(dog_age)) %>%
              group_by(dog_gender) %>%
              summarise(human_years_dog_age = round(mean(dog_age/6)))

colnames(dog_sums) <- c("gender", "age")

dog_years <- table(dog_sums)


#barplot(dog_years,  ylim=c(0,10), ylab="mean dog human years age",main="Barplot of Dog Gender v average age")

plot(dog_years,  ylim=c(0,10), ylab="mean dog human years age", main="Barplot of Dog Gender v average age")
```
End of PDA
